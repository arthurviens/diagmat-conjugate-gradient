#!/bin/bash

### nombre de cores et duree max du job
##OAR -l core=8
#OAR -l core=20, walltime=00:30:00

### nodes reserve pour le TP
##OAR -p host='n-in27' or host='n_in28' or host='n-in29' or host='n-in30' or host='n-in31' or host='n-in35' or host='n-in36' or host='n-in37' or host='n-in39' or host='n-in40'
#OAR -p host='n-in10'

### exemple  par oar
### usage1 : oarsub -S ./tp1.oar
### usage2 : oarsub -l core=120 -S ./tp1.oar

module load gcc9.2
###module load openmpi3.0.1-gcc7.3.0

# Parameter for the study
LOCAL_SZ=100
REP=10

# For debugging, OAR looks really uncomfortable ... ï¿½
# env
# cat $OAR_NODE_FILE
# cat $OAR_RESOURCE_PROPERTIES_FILE

echo "Start computation"
date
# Get the number of MPI tasks
CORES=$(cat $OAR_NODE_FILE | wc -l)
for CORES in 1 2 4 8 12 16 20
do
    echo "Execution on $CORES cores"

    HOSTS=$(cat $OAR_NODE_FILE) ;
    OAR_HOSTS=$(echo $HOSTS | sed "s/ /,/g");

    MPIRUN="$MPI_HOME/bin/mpirun -n $CORES -host $OAR_HOSTS $MPI_PARAM"

    #$MPI_HOME/bin/mpirun -n $CORES -host $OAR_HOSTS $MPI_PARAM tp.out -r $REP -sz $LOCAL_SZ -solver 0
    ### $MPIRUN -np ${n} tp.out -r $REP -solver 2


    for omega in 0.1 0.3 0.5 0.7 0.9 1.0 1.1 1.3 1.5 1.7 1.9
    do
      $MPIRUN ./tp.out -r $REP -solver 3 -precond ${m} -omega ${omega} > ./logs_ssor/np${CORES}_rep${REP}_solver3_m2_omega${omega}.log
      $MPIRUN ./tp.out -r $REP -solver 4 -precond ${m} -omega ${omega} > ./logs_ssor/np${CORES}_rep${REP}_solver4_m2_omega${omega}.log
    done
done
echo "End computation"
